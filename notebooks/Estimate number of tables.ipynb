{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/soda/rcappuzz/work/prepare-data-lakes\n"
     ]
    }
   ],
   "source": [
    "%cd /home/soda/rcappuzz/work/prepare-data-lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import polars.selectors as cs\n",
    "sns.set_theme(\"paper\", style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = pl.Config()\n",
    "cfg.set_fmt_str_lengths(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fields = 2\n",
    "base_path = Path(\"data/yago3-dl/wordnet_vldb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stats = []\n",
    "for path in Path(base_path).glob(\"*.parquet\"):\n",
    "    this_df = pl.read_parquet(path)\n",
    "    rows, cols = this_df.shape\n",
    "    n_num = this_df.select(cs.numeric()).shape[1]\n",
    "    c_num = this_df.select(~cs.numeric()).shape[1]\n",
    "\n",
    "    list_stats.append(\n",
    "        {\n",
    "            \"rows\": rows,\n",
    "            \"cols\": cols,\n",
    "            \"n_num\": n_num,\n",
    "            \"c_num\": c_num,\n",
    "            \"size\": path.stat().st_size,\n",
    "        }\n",
    "    )\n",
    "df_stats = pl.from_dicts(list_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = df_stats.with_columns((pl.col(\"rows\") * pl.col(\"cols\")).alias(\"cells\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>row_median</th><th>col_median</th><th>cell_median</th><th>row_mean</th><th>row_qle</th><th>col_mean</th><th>col_qle</th><th>cell_mean</th><th>cell_qle</th><th>len</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>u32</td></tr></thead><tbody><tr><td>1602.0</td><td>14.0</td><td>21380.0</td><td>28057.108303</td><td>9644.0</td><td>15.945848</td><td>22.0</td><td>969297.974729</td><td>171990.0</td><td>277</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 10)\n",
       "┌────────────┬────────────┬─────────────┬─────────────┬───┬─────────┬─────────────┬──────────┬─────┐\n",
       "│ row_median ┆ col_median ┆ cell_median ┆ row_mean    ┆ … ┆ col_qle ┆ cell_mean   ┆ cell_qle ┆ len │\n",
       "│ ---        ┆ ---        ┆ ---         ┆ ---         ┆   ┆ ---     ┆ ---         ┆ ---      ┆ --- │\n",
       "│ f64        ┆ f64        ┆ f64         ┆ f64         ┆   ┆ f64     ┆ f64         ┆ f64      ┆ u32 │\n",
       "╞════════════╪════════════╪═════════════╪═════════════╪═══╪═════════╪═════════════╪══════════╪═════╡\n",
       "│ 1602.0     ┆ 14.0       ┆ 21380.0     ┆ 28057.10830 ┆ … ┆ 22.0    ┆ 969297.9747 ┆ 171990.0 ┆ 277 │\n",
       "│            ┆            ┆             ┆ 3           ┆   ┆         ┆ 29          ┆          ┆     │\n",
       "└────────────┴────────────┴─────────────┴─────────────┴───┴─────────┴─────────────┴──────────┴─────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats.filter(pl.col(\"cols\") > 8).select(\n",
    "    pl.col(\"rows\").median().alias(\"row_median\"),\n",
    "    pl.col(\"cols\").median().alias(\"col_median\"),\n",
    "    pl.col(\"cells\").median().alias(\"cell_median\"),\n",
    "    pl.col(\"rows\").mean().alias(\"row_mean\"),\n",
    "    pl.col(\"rows\").quantile(0.80).alias(\"row_qle\"),\n",
    "    pl.col(\"cols\").mean().alias(\"col_mean\"),\n",
    "    pl.col(\"cols\").quantile(0.80).alias(\"col_qle\"),\n",
    "    pl.col(\"cells\").mean().alias(\"cell_mean\"),\n",
    "    pl.col(\"cells\").quantile(0.80).alias(\"cell_qle\"),\n",
    "    pl.len(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _size_all_columns(\n",
    "    df_all, resample_rows, resample_columns, row_sample_frac, min_rows=100\n",
    "):\n",
    "    # Total size considering all columns\n",
    "    tot_size_all = (\n",
    "        # select only the tables with enough columns\n",
    "        df_all.with_columns(\n",
    "            # the expected number of rows is given by the starting number of rows\n",
    "            # + the sample fraction x the number of resamplings\n",
    "            exp_rows=pl.col(\"rows\") * ((1 + resample_rows * row_sample_frac)),\n",
    "            # the expected number of columns is the base number of columns - 1 x the number of col resamplings\n",
    "            exp_cols=((pl.col(\"cols\") + pl.col(\"cols\") - 2) / 2) * resample_columns,\n",
    "            # exp_cols=((pl.col(\"cols\") + pl.col(\"cols\") - 2) / 2),\n",
    "        )\n",
    "        # select only the rows that have enough rows\n",
    "        .filter((pl.col(\"exp_rows\") > min_rows)).with_columns(\n",
    "            # the expected number of cells is the product of the expected values\n",
    "            # measured above\n",
    "            exp_cells=pl.col(\"exp_rows\") * pl.col(\"exp_cols\"),\n",
    "            # the average cell size is given by the known size x the known number of cells\n",
    "            cell_size=pl.col(\"size\") / pl.col(\"cells\"),\n",
    "        )\n",
    "        # the expected size is the measured cell size x the number of expected cells\n",
    "        .with_columns(exp_size=pl.col(\"cell_size\") * pl.col(\"exp_cells\"))\n",
    "        # find the total expected size by multiplying the expected size by the number of column\n",
    "        .select((pl.col(\"exp_size\")).sum())\n",
    "        # .select((pl.col(\"exp_size\") * resample_columns).sum())\n",
    "    ).item()\n",
    "    return tot_size_all\n",
    "\n",
    "\n",
    "def _size_num_columns(\n",
    "    df_num, resample_rows, resample_columns, row_sample_frac, min_rows=100\n",
    "):\n",
    "    # base operations are the same, but I am adding a filter\n",
    "    tot_size_num = (\n",
    "        df_num\n",
    "        .with_columns(\n",
    "            exp_rows=pl.col(\"rows\") * ((1 + resample_rows * row_sample_frac)),\n",
    "            min_sample_size=pl.when(pl.col(\"n_num\") > 2)\n",
    "            .then(pl.col(\"n_num\") - 2)\n",
    "            .otherwise(2),\n",
    "            max_sample_size=pl.col(\"n_num\"),\n",
    "        )\n",
    "        .filter((pl.col(\"exp_rows\") > min_rows))\n",
    "        .with_columns(\n",
    "            exp_cols=(pl.col(\"max_sample_size\") + pl.col(\"min_sample_size\"))\n",
    "            / 2\n",
    "            * resample_columns,\n",
    "        )\n",
    "        .with_columns(\n",
    "            exp_cells=pl.col(\"exp_rows\") * pl.col(\"exp_cols\"),\n",
    "            cell_size=pl.col(\"size\") / pl.col(\"cells\"),\n",
    "        )\n",
    "        .with_columns(exp_size=pl.col(\"cell_size\") * pl.col(\"exp_cells\"))\n",
    "        .select((pl.col(\"exp_size\")).sum())\n",
    "    ).item()\n",
    "    return tot_size_num\n",
    "\n",
    "\n",
    "def estimate_size(\n",
    "    df_stats,\n",
    "    resample_rows,\n",
    "    resample_columns,\n",
    "    row_sample_frac=0.7,\n",
    "    min_rows=100,\n",
    "    min_cols=8,\n",
    "):\n",
    "    df_all = df_stats.filter((pl.col(\"cols\") > min_cols))\n",
    "    df_num = df_stats.filter((pl.col(\"cols\") > min_cols) & (pl.col(\"n_num\") >= 2))\n",
    "\n",
    "    params = {\n",
    "        \"resample_rows\": resample_rows,\n",
    "        \"resample_columns\": resample_columns,\n",
    "        \"row_sample_frac\": row_sample_frac,\n",
    "        \"min_rows\": min_rows,\n",
    "    }\n",
    "    \n",
    "    tot_size_all = _size_all_columns(df_all, **params)\n",
    "    tot_size_num = _size_num_columns(df_num, **params)\n",
    "\n",
    "    tot_size = tot_size_all + tot_size_num\n",
    "    return tot_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Number of subtables: 1 - Resamplings by subtable: 2 \n",
      "Approximate size: 0.51 GB\n",
      "Approximate number of tables: 1176\n",
      "##### Number of subtables: 3 - Resamplings by subtable: 2 \n",
      "Approximate size: 1.52 GB\n",
      "Approximate number of tables: 3528\n",
      "##### Number of subtables: 5 - Resamplings by subtable: 2 \n",
      "Approximate size: 2.53 GB\n",
      "Approximate number of tables: 5880\n",
      "##### Number of subtables: 10 - Resamplings by subtable: 2 \n",
      "Approximate size: 5.06 GB\n",
      "Approximate number of tables: 11760\n",
      "##### Number of subtables: 30 - Resamplings by subtable: 2 \n",
      "Approximate size: 15.17 GB\n",
      "Approximate number of tables: 35280\n",
      "##### Number of subtables: 50 - Resamplings by subtable: 2 \n",
      "Approximate size: 25.28 GB\n",
      "Approximate number of tables: 58800\n",
      "##### Number of subtables: 100 - Resamplings by subtable: 2 \n",
      "Approximate size: 50.56 GB\n",
      "Approximate number of tables: 117600\n"
     ]
    }
   ],
   "source": [
    "min_rows = 50\n",
    "min_columns = 8\n",
    "resample_rows = 2\n",
    "\n",
    "for rc in [1, 3, 5, 10, 30, 50, 100]:\n",
    "    tot_size = estimate_size(df_stats, resample_rows, rc)\n",
    "\n",
    "    n_all_tables = len(\n",
    "        df_stats.filter((pl.col(\"rows\") > min_rows) & (pl.col(\"cols\") > min_columns))\n",
    "    )\n",
    "    n_num_tables = len(\n",
    "        df_stats.filter(\n",
    "            (pl.col(\"rows\") > min_rows) & (pl.col(\"cols\") > min_columns)\n",
    "        ).filter(pl.col(\"n_num\") > 2)\n",
    "    )\n",
    "    tot_tables = (n_num_tables + n_all_tables) * (resample_rows + 1) * rc\n",
    "\n",
    "    print(\n",
    "        f\"##### Number of subtables: {rc} - Resamplings by subtable: {resample_rows} \"\n",
    "    )\n",
    "    print(f\"Approximate size: {tot_size/1e9:.2f} GB\")\n",
    "    print(f\"Approximate number of tables: {tot_tables}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
