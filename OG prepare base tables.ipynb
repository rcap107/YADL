{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the base tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook that was used to prepare the base tables for the pipeline in the paper \"A Benchmarking Data Lake \n",
    "for Join Discovery and Learning with Relational Data\".\n",
    "\n",
    "All datasets are inspired from those used in the paper \"[Relational data embeddings for feature enrichment with background information](https://hal.science/hal-03848124/file/main.pdf)\", although some of the matching operations are slightly different.\n",
    "\n",
    "To have more manageable and meaningful tables, some preprocessing is applied to each dataset to reduce overly noisy and \n",
    "irrelevant attributes. \n",
    "\n",
    "All tables are then saved as parquet files for later use in the benchmark pipeline. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets:\n",
    "- [The Movies Dataset](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset)\n",
    "- [7+ Million Company Dataset](https://www.kaggle.com/datasets/peopledatalabssf/free-7-million-company-dataset)\n",
    "- [US Accidents (2016 - 2021)](https://www.kaggle.com/datasets/sobhanmoosavi/us-accidents)\n",
    "- [US Presidential elections](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/42MVDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/soda/rcappuzz/work/prepare-data-lakes\n"
     ]
    }
   ],
   "source": [
    "cd ~/work/prepare-data-lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import src.yago.utils as utils\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading YAGO fact triplets to drop entities not found in the KB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"data/base_tables\")\n",
    "\n",
    "yago_path = Path(\"/storage/store3/work/jstojano/yago3/\")\n",
    "facts_path = Path(yago_path, \"facts_parquet/yago_updated_2022_part2\")\n",
    "fname = \"yagoFacts\"\n",
    "yagofacts_path = Path(facts_path, f\"{fname}.tsv.parquet\")\n",
    "yagofacts_categorical = utils.import_from_yago(yagofacts_path, engine=\"polars\")\n",
    "fname = \"yagoLiteralFacts\"\n",
    "yagoliteralfacts_path = Path(facts_path, f\"{fname}.tsv.parquet\")\n",
    "yagofacts_numerical = utils.import_from_yago(yagoliteralfacts_path, engine=\"polars\")\n",
    "fname = \"yagoDateFacts\"\n",
    "yagodatefacts_path = Path(facts_path, f\"{fname}.tsv.parquet\")\n",
    "yagofacts_dates = utils.import_from_yago(yagodatefacts_path, engine=\"polars\")\n",
    "\n",
    "yagofacts = pl.concat(\n",
    "    [\n",
    "        yagofacts_categorical,\n",
    "        yagofacts_numerical,\n",
    "        yagofacts_dates\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US Accidents dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archive `us-accidents.zip` contains the file `US_Accidents_Dec21_updated.csv`, \n",
    "which I renamed manually to `us-accidents.csv` for simplicity. \n",
    "\n",
    "I also had to copy the file `datasets/us_accidents/state_codes.csv` from the \n",
    "KEN repository for some of the steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(data_dir, \"us-accidents\")\n",
    "df = pl.read_csv(Path(dataset_dir, \"us-accidents.csv\"))\n",
    "df = df.rename({\"State\": \"Code\"})\n",
    "state_codes_path =  Path(dataset_dir,\"state_codes.csv\")\n",
    "state_codes = pl.read_csv(state_codes_path)\n",
    "df = df.join(\n",
    "    state_codes, on=\"Code\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a new column, `col_to_embed`, that formats the city and state name to have\n",
    "the same format that is found in YAGO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "    (\"<\" + pl.col(\"City\") + \",_\"+ pl.col(\"State\") + \">\").alias(\"col_to_embed\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering out the rows not found in `yagofacts[\"subject\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered=df.lazy().filter(\n",
    "    pl.col(\"col_to_embed\").is_in(\n",
    "        yagofacts[\"subject\"]\n",
    "    )\n",
    ").collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the preparation, I am selecting only the accidents whose `Start_Time` is between 2019-01-01 and 2019-12-31. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2019, 1,1)\n",
    "end_date = datetime.date(2019, 12, 31)\n",
    "df_by_year = df_filtered.filter(\n",
    "    (pl.col(\"Start_Time\").str.to_datetime()>start_date) & (pl.col(\"Start_Time\").str.to_datetime()<end_date)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the number of accidents (log10) per county in the given year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5_222, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>col_to_embed</th><th>target</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;&lt;Yarmouth,_Mai…</td><td>1.278754</td></tr><tr><td>&quot;&lt;Mundelein,_Il…</td><td>1.919078</td></tr><tr><td>&quot;&lt;Parker,_Color…</td><td>1.819544</td></tr><tr><td>&quot;&lt;Springfield,_…</td><td>2.447158</td></tr><tr><td>&quot;&lt;Corvallis,_Or…</td><td>2.170262</td></tr><tr><td>&quot;&lt;Patterson,_Ca…</td><td>2.004321</td></tr><tr><td>&quot;&lt;Berkeley,_Cal…</td><td>2.488551</td></tr><tr><td>&quot;&lt;McArthur,_Cal…</td><td>1.113943</td></tr><tr><td>&quot;&lt;Lynwood,_Cali…</td><td>2.416641</td></tr><tr><td>&quot;&lt;Boron,_Califo…</td><td>1.491362</td></tr><tr><td>&quot;&lt;Redlands,_Cal…</td><td>2.69897</td></tr><tr><td>&quot;&lt;Victorville,_…</td><td>2.100371</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;&lt;Filer,_Idaho&gt;…</td><td>0.30103</td></tr><tr><td>&quot;&lt;Lincoln,_Arka…</td><td>0.0</td></tr><tr><td>&quot;&lt;Rockville,_In…</td><td>0.477121</td></tr><tr><td>&quot;&lt;Colville,_Was…</td><td>0.0</td></tr><tr><td>&quot;&lt;Larwill,_Indi…</td><td>0.69897</td></tr><tr><td>&quot;&lt;Deary,_Idaho&gt;…</td><td>0.30103</td></tr><tr><td>&quot;&lt;Arriba,_Color…</td><td>0.30103</td></tr><tr><td>&quot;&lt;Elsinore,_Uta…</td><td>0.30103</td></tr><tr><td>&quot;&lt;Goshen,_Virgi…</td><td>0.0</td></tr><tr><td>&quot;&lt;Eastlake,_Ohi…</td><td>0.0</td></tr><tr><td>&quot;&lt;Fitchburg,_Wi…</td><td>0.0</td></tr><tr><td>&quot;&lt;Veedersburg,_…</td><td>0.477121</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5_222, 2)\n",
       "┌────────────────────────┬──────────┐\n",
       "│ col_to_embed           ┆ target   │\n",
       "│ ---                    ┆ ---      │\n",
       "│ str                    ┆ f64      │\n",
       "╞════════════════════════╪══════════╡\n",
       "│ <Yarmouth,_Maine>      ┆ 1.278754 │\n",
       "│ <Mundelein,_Illinois>  ┆ 1.919078 │\n",
       "│ <Parker,_Colorado>     ┆ 1.819544 │\n",
       "│ <Springfield,_Oregon>  ┆ 2.447158 │\n",
       "│ …                      ┆ …        │\n",
       "│ <Goshen,_Virginia>     ┆ 0.0      │\n",
       "│ <Eastlake,_Ohio>       ┆ 0.0      │\n",
       "│ <Fitchburg,_Wisconsin> ┆ 0.0      │\n",
       "│ <Veedersburg,_Indiana> ┆ 0.477121 │\n",
       "└────────────────────────┴──────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_counts_by_year=df_by_year.groupby(\n",
    "    [\n",
    "        \"col_to_embed\", \"City\", \"Code\"\n",
    "    ]\n",
    "    ).count().select(\n",
    "        pl.col(\"col_to_embed\"),\n",
    "        pl.col(\"count\").alias(\"target\").log10()\n",
    "    )\n",
    "df_counts_by_year"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the KEN paper, everything except the county was dropped. Here, we need to rely on the information still found in the \n",
    "table, so we need to to reduce the table to have only one sample for each row. It is necessary to aggregate any information\n",
    "that has granularity smaller than \"county\". \n",
    "\n",
    "The overall number of columns is also reduced from the original. \n",
    "\n",
    "To aggregate all the values, the `mode` is used to select the most frequent categorical value, while the `mean` is used\n",
    "on the numerical attributes. \n",
    "\n",
    "The resulting table is saved in `us-accidents-yadl.parquet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=df_counts_by_year.join(\n",
    "    df_by_year, \n",
    "    on=\"col_to_embed\",\n",
    "    how=\"inner\"\n",
    ").groupby(\"col_to_embed\").agg(\n",
    "    pl.col(\"target\").mean(),\n",
    "    pl.col(\"County\").mode().first(),\n",
    "    pl.col(\"Code\").mode().first(),\n",
    "    pl.col(\"Severity\").mean(),\n",
    "    pl.col(\"Zipcode\").mode().first(),\n",
    "    pl.col(\"Country\").mode().first(),\n",
    "    pl.col(\"Airport_Code\").mode().first(),\n",
    "    pl.col(\"Visibility(mi)\").mean(),\n",
    "    pl.col(\"Weather_Condition\").mean(),\n",
    "    pl.col(\"Sunrise_Sunset\").mode().first(),\n",
    "    pl.col(\"Civil_Twilight\").mode().first(),\n",
    "    pl.col(\"State\").mode().first(),    \n",
    ")\n",
    "df_final.write_parquet(Path(dataset_dir, \"us-accidents-yadl.parquet\"))\n",
    "df_final.write_csv(Path(dataset_dir, \"us-accidents-yadl.csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing with the KEN version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we prepare the table using the same operations as those made for KEN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts = df_filtered.groupby(\n",
    "    [\n",
    "        \"col_to_embed\", \"City\", \"Code\"\n",
    "    ]\n",
    "    ).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_counts.with_columns(\n",
    "    (df_counts[\"City\"] + \", \" + df_counts[\"Code\"]).alias(\"raw_entities\") \n",
    ").select(\n",
    "    [\n",
    "        pl.col(\"raw_entities\"),\n",
    "        pl.col(\"col_to_embed\"),\n",
    "        pl.col(\"count\").alias(\"target\").log10()\n",
    "    ]\n",
    ").sort(\"raw_entities\")\n",
    "df_final.write_parquet(Path(dataset_dir, \"us-accidents-target.parquet\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading original to see if the two versions look similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8_538, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>raw_entities</th><th>col_to_embed</th><th>target</th></tr><tr><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Aaronsburg, PA…</td><td>&quot;&lt;Aaronsburg,_P…</td><td>0.30103</td></tr><tr><td>&quot;Abbeville, LA&quot;</td><td>&quot;&lt;Abbeville,_Lo…</td><td>0.0</td></tr><tr><td>&quot;Abbotsford, WI…</td><td>&quot;&lt;Abbotsford,_W…</td><td>0.954243</td></tr><tr><td>&quot;Abbottstown, P…</td><td>&quot;&lt;Abbottstown,_…</td><td>1.041393</td></tr><tr><td>&quot;Aberdeen, MD&quot;</td><td>&quot;&lt;Aberdeen,_Mar…</td><td>2.396199</td></tr><tr><td>&quot;Aberdeen, MS&quot;</td><td>&quot;&lt;Aberdeen,_Mis…</td><td>0.477121</td></tr><tr><td>&quot;Aberdeen, OH&quot;</td><td>&quot;&lt;Aberdeen,_Ohi…</td><td>0.0</td></tr><tr><td>&quot;Aberdeen, WA&quot;</td><td>&quot;&lt;Aberdeen,_Was…</td><td>1.342423</td></tr><tr><td>&quot;Abernathy, TX&quot;</td><td>&quot;&lt;Abernathy,_Te…</td><td>0.0</td></tr><tr><td>&quot;Abilene, TX&quot;</td><td>&quot;&lt;Abilene,_Texa…</td><td>1.0</td></tr><tr><td>&quot;Abingdon, MD&quot;</td><td>&quot;&lt;Abingdon,_Mar…</td><td>2.136721</td></tr><tr><td>&quot;Abingdon, VA&quot;</td><td>&quot;&lt;Abingdon,_Vir…</td><td>2.064458</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Zeeland, MI&quot;</td><td>&quot;&lt;Zeeland,_Mich…</td><td>1.662758</td></tr><tr><td>&quot;Zelienople, PA…</td><td>&quot;&lt;Zelienople,_P…</td><td>1.079181</td></tr><tr><td>&quot;Zellwood, FL&quot;</td><td>&quot;&lt;Zellwood,_Flo…</td><td>1.591065</td></tr><tr><td>&quot;Zephyrhills, F…</td><td>&quot;&lt;Zephyrhills,_…</td><td>2.08636</td></tr><tr><td>&quot;Zillah, WA&quot;</td><td>&quot;&lt;Zillah,_Washi…</td><td>0.60206</td></tr><tr><td>&quot;Zimmerman, MN&quot;</td><td>&quot;&lt;Zimmerman,_Mi…</td><td>1.812913</td></tr><tr><td>&quot;Zion, IL&quot;</td><td>&quot;&lt;Zion,_Illinoi…</td><td>2.50515</td></tr><tr><td>&quot;Zionsville, IN…</td><td>&quot;&lt;Zionsville,_I…</td><td>2.190332</td></tr><tr><td>&quot;Zionsville, PA…</td><td>&quot;&lt;Zionsville,_P…</td><td>0.0</td></tr><tr><td>&quot;Zumbrota, MN&quot;</td><td>&quot;&lt;Zumbrota,_Min…</td><td>2.193125</td></tr><tr><td>&quot;Zuni, VA&quot;</td><td>&quot;&lt;Zuni,_Virgini…</td><td>1.079181</td></tr><tr><td>&quot;Zwingle, IA&quot;</td><td>&quot;&lt;Zwingle,_Iowa…</td><td>0.60206</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8_538, 3)\n",
       "┌─────────────────┬─────────────────────────────┬──────────┐\n",
       "│ raw_entities    ┆ col_to_embed                ┆ target   │\n",
       "│ ---             ┆ ---                         ┆ ---      │\n",
       "│ str             ┆ str                         ┆ f64      │\n",
       "╞═════════════════╪═════════════════════════════╪══════════╡\n",
       "│ Aaronsburg, PA  ┆ <Aaronsburg,_Pennsylvania>  ┆ 0.30103  │\n",
       "│ Abbeville, LA   ┆ <Abbeville,_Louisiana>      ┆ 0.0      │\n",
       "│ Abbotsford, WI  ┆ <Abbotsford,_Wisconsin>     ┆ 0.954243 │\n",
       "│ Abbottstown, PA ┆ <Abbottstown,_Pennsylvania> ┆ 1.041393 │\n",
       "│ …               ┆ …                           ┆ …        │\n",
       "│ Zionsville, PA  ┆ <Zionsville,_Pennsylvania>  ┆ 0.0      │\n",
       "│ Zumbrota, MN    ┆ <Zumbrota,_Minnesota>       ┆ 2.193125 │\n",
       "│ Zuni, VA        ┆ <Zuni,_Virginia>            ┆ 1.079181 │\n",
       "│ Zwingle, IA     ┆ <Zwingle,_Iowa>             ┆ 0.60206  │\n",
       "└─────────────────┴─────────────────────────────┴──────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_original=Path(\"/storage/store3/work/acvetkov/gitlab/KEN/experiments/datasets/us_accidents/counts.parquet\")\n",
    "df_counts_og = pl.read_parquet(path_original)\n",
    "df_counts_og"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the number of entities in the original file is smaller. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company Employees Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Company Employees\" dataset contains information about companies. The prediction target in this case is the number \n",
    "of employees of a company. We filter the dataset to select only companies with at least 1000 employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(data_dir, \"company-employees\")\n",
    "df = pl.read_csv(Path(dataset_dir, \"companies_sorted.csv\"))\n",
    "df_selected = df.filter(\n",
    "    pl.col(\"current employee estimate\") >= 1000\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heuristic we use is slightly different from that used for KEN. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a new column to `yagofacts` with lowercased subjects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "yagofacts = yagofacts.with_columns(\n",
    "    pl.col(\"subject\").str.to_lowercase().alias(\"subject_formatted\")\n",
    ")\n",
    "df_filtered=df_selected.lazy().with_columns(\n",
    "    (\"<\" + pl.col(\"name\").str.to_lowercase().str.replace(\" \", \"_\") + \">\").alias(\"formatted_name\")\n",
    ").filter(\n",
    "    pl.col(\"formatted_name\").is_in(yagofacts[\"subject_formatted\"])\n",
    ").collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we prepare a mapping between the name in the original dataset and the match found in YAGO.\n",
    "Note that there is a relatively low recall, though it is higher than what is used in the original. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_name_subject = df_filtered.lazy().join(\n",
    "    yagofacts.lazy(),\n",
    "    left_on=\"formatted_name\",\n",
    "    right_on=\"subject_formatted\"\n",
    ").select(\n",
    "    [\n",
    "        pl.col(\"name\"),\n",
    "        pl.col(\"formatted_name\"),\n",
    "        pl.col(\"subject\")\n",
    "    ]\n",
    ").unique().collect()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining on with the mapping on `formatted_name` to guarantee that col `col_to_embed` uses the same format (and \n",
    "capitalization) used in YAGO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3_035, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>raw_entities</th><th>col_to_embed</th><th>target</th></tr><tr><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;ibm&quot;</td><td>&quot;&lt;IBM&gt;&quot;</td><td>5.437825</td></tr><tr><td>&quot;accenture&quot;</td><td>&quot;&lt;Accenture&gt;&quot;</td><td>5.280326</td></tr><tr><td>&quot;hewlett-packar…</td><td>&quot;&lt;Hewlett-Packa…</td><td>5.107047</td></tr><tr><td>&quot;walmart&quot;</td><td>&quot;&lt;Walmart&gt;&quot;</td><td>5.081898</td></tr><tr><td>&quot;microsoft&quot;</td><td>&quot;&lt;Microsoft&gt;&quot;</td><td>5.065191</td></tr><tr><td>&quot;at&amp;t&quot;</td><td>&quot;&lt;AT&amp;T&gt;&quot;</td><td>5.061407</td></tr><tr><td>&quot;wells fargo&quot;</td><td>&quot;&lt;Wells_Fargo&gt;&quot;</td><td>5.039541</td></tr><tr><td>&quot;infosys&quot;</td><td>&quot;&lt;Infosys&gt;&quot;</td><td>5.020162</td></tr><tr><td>&quot;deloitte&quot;</td><td>&quot;&lt;Deloitte&gt;&quot;</td><td>5.017501</td></tr><tr><td>&quot;nokia&quot;</td><td>&quot;&lt;Nokia&gt;&quot;</td><td>4.925967</td></tr><tr><td>&quot;capgemini&quot;</td><td>&quot;&lt;Capgemini&gt;&quot;</td><td>4.925204</td></tr><tr><td>&quot;hsbc&quot;</td><td>&quot;&lt;HSBC&gt;&quot;</td><td>4.878752</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;vilnius univer…</td><td>&quot;&lt;Vilnius_Unive…</td><td>3.002598</td></tr><tr><td>&quot;moody&#x27;s corpor…</td><td>&quot;&lt;Moody&#x27;s_Corpo…</td><td>3.002598</td></tr><tr><td>&quot;air europa&quot;</td><td>&quot;&lt;Air_Europa&gt;&quot;</td><td>3.002166</td></tr><tr><td>&quot;providence col…</td><td>&quot;&lt;Providence_Co…</td><td>3.002166</td></tr><tr><td>&quot;appdynamics&quot;</td><td>&quot;&lt;AppDynamics&gt;&quot;</td><td>3.002166</td></tr><tr><td>&quot;qihoo 360&quot;</td><td>&quot;&lt;Qihoo_360&gt;&quot;</td><td>3.002166</td></tr><tr><td>&quot;hubbell incorp…</td><td>&quot;&lt;Hubbell_Incor…</td><td>3.001301</td></tr><tr><td>&quot;revenu québec&quot;</td><td>&quot;&lt;Revenu_Québec…</td><td>3.000868</td></tr><tr><td>&quot;jagiellonian u…</td><td>&quot;&lt;Jagiellonian_…</td><td>3.000434</td></tr><tr><td>&quot;becu&quot;</td><td>&quot;&lt;BECU&gt;&quot;</td><td>3.0</td></tr><tr><td>&quot;sta travel&quot;</td><td>&quot;&lt;STA_Travel&gt;&quot;</td><td>3.0</td></tr><tr><td>&quot;megacable&quot;</td><td>&quot;&lt;Megacable&gt;&quot;</td><td>3.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3_035, 3)\n",
       "┌─────────────────────────┬───────────────────────────┬──────────┐\n",
       "│ raw_entities            ┆ col_to_embed              ┆ target   │\n",
       "│ ---                     ┆ ---                       ┆ ---      │\n",
       "│ str                     ┆ str                       ┆ f64      │\n",
       "╞═════════════════════════╪═══════════════════════════╪══════════╡\n",
       "│ ibm                     ┆ <IBM>                     ┆ 5.437825 │\n",
       "│ accenture               ┆ <Accenture>               ┆ 5.280326 │\n",
       "│ hewlett-packard         ┆ <Hewlett-Packard>         ┆ 5.107047 │\n",
       "│ walmart                 ┆ <Walmart>                 ┆ 5.081898 │\n",
       "│ …                       ┆ …                         ┆ …        │\n",
       "│ jagiellonian university ┆ <Jagiellonian_University> ┆ 3.000434 │\n",
       "│ becu                    ┆ <BECU>                    ┆ 3.0      │\n",
       "│ sta travel              ┆ <STA_Travel>              ┆ 3.0      │\n",
       "│ megacable               ┆ <Megacable>               ┆ 3.0      │\n",
       "└─────────────────────────┴───────────────────────────┴──────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df_filtered.join(\n",
    "    mapping_name_subject, on=\"formatted_name\"\n",
    ").select(\n",
    "    [\n",
    "        pl.col(\"name\").alias(\"raw_entities\"),\n",
    "        pl.col(\"subject\").alias(\"col_to_embed\"),\n",
    "        pl.col(\"current employee estimate\").alias(\"target\").log10()\n",
    "    ]\n",
    ")\n",
    "df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.write_parquet(Path(dataset_dir, \"company-employees-target.parquet\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining the measure target on the base table. Some unnecessary columns are dropped from the table, then it is saved on disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepared = df_filtered.lazy().join(\n",
    "    df_final.lazy(),\n",
    "    left_on=\"name\",\n",
    "    right_on=\"raw_entities\",\n",
    "    how=\"inner\"\n",
    ").drop(\n",
    "    \"\",\n",
    "    \"formatted_name\",\n",
    "    \"current employee estimate\",\n",
    "    \"total employee estimate\",\n",
    ").collect()\n",
    "df_prepared.write_parquet(Path(dataset_dir, \"company-employees-yadl.parquet\"))\n",
    "df_prepared.write_csv(Path(dataset_dir, \"company-employees-yadl.csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing with the original. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3_042, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>raw_entities</th><th>col_to_embed</th><th>target</th></tr><tr><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;accenture&quot;</td><td>&quot;&lt;Accenture&gt;&quot;</td><td>5.280326</td></tr><tr><td>&quot;walmart&quot;</td><td>&quot;&lt;Walmart&gt;&quot;</td><td>5.081898</td></tr><tr><td>&quot;microsoft&quot;</td><td>&quot;&lt;Microsoft&gt;&quot;</td><td>5.065191</td></tr><tr><td>&quot;infosys&quot;</td><td>&quot;&lt;Infosys&gt;&quot;</td><td>5.020162</td></tr><tr><td>&quot;deloitte&quot;</td><td>&quot;&lt;Deloitte&gt;&quot;</td><td>5.017501</td></tr><tr><td>&quot;nokia&quot;</td><td>&quot;&lt;Nokia&gt;&quot;</td><td>4.925967</td></tr><tr><td>&quot;capgemini&quot;</td><td>&quot;&lt;Capgemini&gt;&quot;</td><td>4.925204</td></tr><tr><td>&quot;google&quot;</td><td>&quot;&lt;Google&gt;&quot;</td><td>4.875692</td></tr><tr><td>&quot;ericsson&quot;</td><td>&quot;&lt;Ericsson&gt;&quot;</td><td>4.830537</td></tr><tr><td>&quot;boeing&quot;</td><td>&quot;&lt;Boeing&gt;&quot;</td><td>4.827763</td></tr><tr><td>&quot;vodafone&quot;</td><td>&quot;&lt;Vodafone&gt;&quot;</td><td>4.823683</td></tr><tr><td>&quot;pfizer&quot;</td><td>&quot;&lt;Pfizer&gt;&quot;</td><td>4.775159</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;kfc&quot;</td><td>&quot;&lt;KFC&gt;&quot;</td><td>3.081347</td></tr><tr><td>&quot;fifa&quot;</td><td>&quot;&lt;FIFA&gt;&quot;</td><td>3.075547</td></tr><tr><td>&quot;yit&quot;</td><td>&quot;&lt;YIT&gt;&quot;</td><td>3.068186</td></tr><tr><td>&quot;kplc&quot;</td><td>&quot;&lt;KPLC&gt;&quot;</td><td>3.064458</td></tr><tr><td>&quot;nbty&quot;</td><td>&quot;&lt;NBTY&gt;&quot;</td><td>3.061829</td></tr><tr><td>&quot;tdk&quot;</td><td>&quot;&lt;TDK&gt;&quot;</td><td>3.049993</td></tr><tr><td>&quot;vtb&quot;</td><td>&quot;&lt;VTB&gt;&quot;</td><td>3.043755</td></tr><tr><td>&quot;zdf&quot;</td><td>&quot;&lt;ZDF&gt;&quot;</td><td>3.0306</td></tr><tr><td>&quot;xml&quot;</td><td>&quot;&lt;XML&gt;&quot;</td><td>3.022841</td></tr><tr><td>&quot;posco&quot;</td><td>&quot;&lt;POSCO&gt;&quot;</td><td>3.006894</td></tr><tr><td>&quot;oncf&quot;</td><td>&quot;&lt;ONCF&gt;&quot;</td><td>3.006466</td></tr><tr><td>&quot;becu&quot;</td><td>&quot;&lt;BECU&gt;&quot;</td><td>3.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3_042, 3)\n",
       "┌──────────────┬──────────────┬──────────┐\n",
       "│ raw_entities ┆ col_to_embed ┆ target   │\n",
       "│ ---          ┆ ---          ┆ ---      │\n",
       "│ str          ┆ str          ┆ f64      │\n",
       "╞══════════════╪══════════════╪══════════╡\n",
       "│ accenture    ┆ <Accenture>  ┆ 5.280326 │\n",
       "│ walmart      ┆ <Walmart>    ┆ 5.081898 │\n",
       "│ microsoft    ┆ <Microsoft>  ┆ 5.065191 │\n",
       "│ infosys      ┆ <Infosys>    ┆ 5.020162 │\n",
       "│ …            ┆ …            ┆ …        │\n",
       "│ xml          ┆ <XML>        ┆ 3.022841 │\n",
       "│ posco        ┆ <POSCO>      ┆ 3.006894 │\n",
       "│ oncf         ┆ <ONCF>       ┆ 3.006466 │\n",
       "│ becu         ┆ <BECU>       ┆ 3.0      │\n",
       "└──────────────┴──────────────┴──────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_original=Path(\"/storage/store3/work/acvetkov/gitlab/KEN/experiments/datasets/company_employees/target.parquet\")\n",
    "df_target_og = pl.read_parquet(path_original)\n",
    "df_target_og"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are checking which values in `col_to_embed` are not found in `yagofacts[\"subject\"]`. These companies are missing \n",
    "because the name of the company is not the same in the original dataset and in YAGO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (327, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>raw_entities</th><th>col_to_embed</th><th>target</th></tr><tr><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;raytheon&quot;</td><td>&quot;&lt;Raytheon&gt;&quot;</td><td>4.375353</td></tr><tr><td>&quot;thales&quot;</td><td>&quot;&lt;Thales&gt;&quot;</td><td>4.321868</td></tr><tr><td>&quot;herbalife&quot;</td><td>&quot;&lt;Herbalife&gt;&quot;</td><td>4.289433</td></tr><tr><td>&quot;flextronics&quot;</td><td>&quot;&lt;Flextronics&gt;&quot;</td><td>4.279644</td></tr><tr><td>&quot;adecco&quot;</td><td>&quot;&lt;Adecco&gt;&quot;</td><td>4.160799</td></tr><tr><td>&quot;altran&quot;</td><td>&quot;&lt;Altran&gt;&quot;</td><td>4.090187</td></tr><tr><td>&quot;statoil&quot;</td><td>&quot;&lt;Statoil&gt;&quot;</td><td>4.081563</td></tr><tr><td>&quot;symantec&quot;</td><td>&quot;&lt;Symantec&gt;&quot;</td><td>4.034628</td></tr><tr><td>&quot;syntel&quot;</td><td>&quot;&lt;Syntel&gt;&quot;</td><td>3.994229</td></tr><tr><td>&quot;arup&quot;</td><td>&quot;&lt;Arup&gt;&quot;</td><td>3.98304</td></tr><tr><td>&quot;natura&quot;</td><td>&quot;&lt;Natura&gt;&quot;</td><td>3.972295</td></tr><tr><td>&quot;tieto&quot;</td><td>&quot;&lt;Tieto&gt;&quot;</td><td>3.93922</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;itv&quot;</td><td>&quot;&lt;ITV&gt;&quot;</td><td>3.562174</td></tr><tr><td>&quot;nasdaq&quot;</td><td>&quot;&lt;NASDAQ&gt;&quot;</td><td>3.482588</td></tr><tr><td>&quot;aselsan&quot;</td><td>&quot;&lt;ASELSAN&gt;&quot;</td><td>3.397071</td></tr><tr><td>&quot;meditech&quot;</td><td>&quot;&lt;MEDITECH&gt;&quot;</td><td>3.329194</td></tr><tr><td>&quot;jysk&quot;</td><td>&quot;&lt;JYSK&gt;&quot;</td><td>3.256477</td></tr><tr><td>&quot;sabb&quot;</td><td>&quot;&lt;SABB&gt;&quot;</td><td>3.190051</td></tr><tr><td>&quot;sagemcom&quot;</td><td>&quot;&lt;SAGEMCOM&gt;&quot;</td><td>3.155943</td></tr><tr><td>&quot;chesf&quot;</td><td>&quot;&lt;CHESF&gt;&quot;</td><td>3.150142</td></tr><tr><td>&quot;oneok&quot;</td><td>&quot;&lt;ONEOK&gt;&quot;</td><td>3.134177</td></tr><tr><td>&quot;trt&quot;</td><td>&quot;&lt;TRT&gt;&quot;</td><td>3.117271</td></tr><tr><td>&quot;nbty&quot;</td><td>&quot;&lt;NBTY&gt;&quot;</td><td>3.061829</td></tr><tr><td>&quot;vtb&quot;</td><td>&quot;&lt;VTB&gt;&quot;</td><td>3.043755</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (327, 3)\n",
       "┌──────────────┬───────────────┬──────────┐\n",
       "│ raw_entities ┆ col_to_embed  ┆ target   │\n",
       "│ ---          ┆ ---           ┆ ---      │\n",
       "│ str          ┆ str           ┆ f64      │\n",
       "╞══════════════╪═══════════════╪══════════╡\n",
       "│ raytheon     ┆ <Raytheon>    ┆ 4.375353 │\n",
       "│ thales       ┆ <Thales>      ┆ 4.321868 │\n",
       "│ herbalife    ┆ <Herbalife>   ┆ 4.289433 │\n",
       "│ flextronics  ┆ <Flextronics> ┆ 4.279644 │\n",
       "│ …            ┆ …             ┆ …        │\n",
       "│ oneok        ┆ <ONEOK>       ┆ 3.134177 │\n",
       "│ trt          ┆ <TRT>         ┆ 3.117271 │\n",
       "│ nbty         ┆ <NBTY>        ┆ 3.061829 │\n",
       "│ vtb          ┆ <VTB>         ┆ 3.043755 │\n",
       "└──────────────┴───────────────┴──────────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target_og.filter(\n",
    "    ~pl.col(\"col_to_embed\").is_in(yagofacts[\"subject\"])\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Movies Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Movies Dataset contains metadata about movies, including the revenue, which is the prediction target for this problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(data_dir, \"the-movies-dataset\")\n",
    "df = pl.read_csv(Path(dataset_dir, \"movies_metadata.csv\"), infer_schema_length=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the target variable is the revenue, movies with revenue 0 are dropped. We are also reformatting the release date for creating the title mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering\n",
    "df_filtered = df.filter(\n",
    "    pl.col(\"revenue\").cast(int) > 0\n",
    ").with_columns(\n",
    "    (pl.col(\"release_date\").str.slice(0, 4)).alias(\"release_date\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`title` and `release_date` together should approximate a unique key quite well: I am looking to see whether this is the case or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7_398, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>title</th><th>release_date</th><th>count</th></tr><tr><td>str</td><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;The Congress&quot;</td><td>&quot;2013&quot;</td><td>2</td></tr><tr><td>&quot;Confessions of…</td><td>&quot;2002&quot;</td><td>2</td></tr><tr><td>&quot;Le Samouraï&quot;</td><td>&quot;1967&quot;</td><td>2</td></tr><tr><td>&quot;Pokémon: Spell…</td><td>&quot;2000&quot;</td><td>2</td></tr><tr><td>&quot;Black Gold&quot;</td><td>&quot;2011&quot;</td><td>2</td></tr><tr><td>&quot;Clockstoppers&quot;</td><td>&quot;2002&quot;</td><td>2</td></tr><tr><td>&quot;Force Majeure&quot;</td><td>&quot;2014&quot;</td><td>2</td></tr><tr><td>&quot;Pokémon 4Ever:…</td><td>&quot;2001&quot;</td><td>2</td></tr><tr><td>&quot;A Farewell to …</td><td>&quot;1932&quot;</td><td>2</td></tr><tr><td>&quot;Camille Claude…</td><td>&quot;2013&quot;</td><td>2</td></tr><tr><td>&quot;Mighty Aphrodi…</td><td>&quot;1995&quot;</td><td>1</td></tr><tr><td>&quot;Nick of Time&quot;</td><td>&quot;1995&quot;</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Bangalore Days…</td><td>&quot;2014&quot;</td><td>1</td></tr><tr><td>&quot;Dilwale&quot;</td><td>&quot;2015&quot;</td><td>1</td></tr><tr><td>&quot;What the Bleep…</td><td>&quot;2006&quot;</td><td>1</td></tr><tr><td>&quot;Love &amp; Friends…</td><td>&quot;2016&quot;</td><td>1</td></tr><tr><td>&quot;The Lonely Lad…</td><td>&quot;1983&quot;</td><td>1</td></tr><tr><td>&quot;The Purge: Ele…</td><td>&quot;2016&quot;</td><td>1</td></tr><tr><td>&quot;Loving&quot;</td><td>&quot;2016&quot;</td><td>1</td></tr><tr><td>&quot;Broken Hill&quot;</td><td>&quot;2009&quot;</td><td>1</td></tr><tr><td>&quot;Jack Reacher: …</td><td>&quot;2016&quot;</td><td>1</td></tr><tr><td>&quot;The Wall&quot;</td><td>&quot;2017&quot;</td><td>1</td></tr><tr><td>&quot;Chelovek, koto…</td><td>&quot;2009&quot;</td><td>1</td></tr><tr><td>&quot;Bairavaa&quot;</td><td>&quot;2017&quot;</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7_398, 3)\n",
       "┌─────────────────────────────────┬──────────────┬───────┐\n",
       "│ title                           ┆ release_date ┆ count │\n",
       "│ ---                             ┆ ---          ┆ ---   │\n",
       "│ str                             ┆ str          ┆ u32   │\n",
       "╞═════════════════════════════════╪══════════════╪═══════╡\n",
       "│ The Congress                    ┆ 2013         ┆ 2     │\n",
       "│ Confessions of a Dangerous Mind ┆ 2002         ┆ 2     │\n",
       "│ Le Samouraï                     ┆ 1967         ┆ 2     │\n",
       "│ Pokémon: Spell of the Unknown   ┆ 2000         ┆ 2     │\n",
       "│ …                               ┆ …            ┆ …     │\n",
       "│ Jack Reacher: Never Go Back     ┆ 2016         ┆ 1     │\n",
       "│ The Wall                        ┆ 2017         ┆ 1     │\n",
       "│ Chelovek, kotoryy znal vsyo     ┆ 2009         ┆ 1     │\n",
       "│ Bairavaa                        ┆ 2017         ┆ 1     │\n",
       "└─────────────────────────────────┴──────────────┴───────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.groupby([\"title\", \"release_date\"]).count().sort(\"count\",descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare 3 different mappings, to try and cover as many cases as possible\n",
    "mapping_to_yago = df_filtered.select([pl.col(\"title\"), pl.col(\"release_date\"), pl.col(\"revenue\")])\n",
    "\n",
    "mapping_to_yago=mapping_to_yago.with_columns(\n",
    "    [\n",
    "        (\"<\" + pl.col(\"title\").str.replace(\" \", \"_\") + \">\").alias(\"title_format_1\"),\n",
    "        (\"<\" + pl.col(\"title\").str.replace(\" \", \"_\") + \"_(film)>\").alias(\"title_format_2\"),\n",
    "        (\"<\" + pl.col(\"title\").str.replace(\" \", \"_\") +  \"_(\" + pl.col(\"release_date\") + \"_film)>\").alias(\"title_format_3\"),\n",
    "        pl.Series(list(range(len(mapping_to_yago)))).alias(\"index\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are looking for movies that are present in YAGO according to one of the three formats defined above. \n",
    "\n",
    "we also reformat the output to reflect the \"target dataset\" schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_indices = []\n",
    "selected = []\n",
    "for jj in [3,2,1]:\n",
    "    g1 = mapping_to_yago.filter(\n",
    "        (pl.col(f\"title_format_{jj}\").is_in(yagofacts[\"subject\"])) & \n",
    "        (~pl.col(f\"index\").is_in(tgt_indices))\n",
    "    ).select(pl.col(\"index\"))\n",
    "\n",
    "    tgt_indices=g1[\"index\"].to_list()\n",
    "    \n",
    "    newdf = mapping_to_yago.filter(\n",
    "        pl.col(\"index\").is_in(tgt_indices)\n",
    "    ).select(\n",
    "        [\n",
    "            pl.col(\"title\"),\n",
    "            pl.col(\"release_date\"),\n",
    "            pl.col(f\"title_format_{jj}\").alias(\"col_to_embed\"),\n",
    "            pl.col(\"revenue\").log10(),\n",
    "        ]\n",
    "    )\n",
    "    selected.append(newdf)\n",
    "\n",
    "df_final=pl.concat(selected)\n",
    "df_final.write_parquet(Path(dataset_dir, \"movie-revenues-target.parquet\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some preprocessing must be executed in order to flatten the nested fields in the dataset. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def clean_genres(ll):\n",
    "    g = ast.literal_eval(ll)\n",
    "    try:\n",
    "        l1 = g[0][\"name\"]\n",
    "        return l1\n",
    "    except IndexError:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def clean_production_companies(ll):\n",
    "    try:\n",
    "        g = ast.literal_eval(ll)\n",
    "    except ValueError:\n",
    "        return \"\"\n",
    "    except SyntaxError:\n",
    "        print(ll)\n",
    "    try:\n",
    "        l1 = g[0][\"name\"]\n",
    "        return l1\n",
    "    except IndexError:\n",
    "        return \"\"\n",
    "    except TypeError:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def clean_production_country(ll):\n",
    "    try:\n",
    "        g = ast.literal_eval(ll)\n",
    "    except ValueError:\n",
    "        return \"\"\n",
    "    try:\n",
    "        l1 = g[0][\"iso_3166_1\"]\n",
    "        return l1\n",
    "    except IndexError:\n",
    "        return \"\"\n",
    "    except TypeError:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def clean_spoken_language(ll):\n",
    "    try:\n",
    "        g = ast.literal_eval(ll)\n",
    "    except ValueError:\n",
    "        return \"\"\n",
    "    try:\n",
    "        l1 = g[0][\"name\"]\n",
    "        return l1\n",
    "    except IndexError:\n",
    "        return \"\"\n",
    "    except TypeError:\n",
    "        return \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_filtered.lazy().join(df_final.lazy(), left_on=[\"title\", \"release_date\"], right_on=[\"title\", \"release_date\"], how=\"inner\").collect().to_pandas()\n",
    "df = df.drop(\n",
    "    [\n",
    "        \"belongs_to_collection\",\n",
    "        \"homepage\",\n",
    "        \"imdb_id\",\n",
    "        \"overview\",\n",
    "        \"tagline\",\n",
    "        \"poster_path\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df.genres = df.genres.apply(clean_genres)\n",
    "df.production_companies = df.production_companies.apply(clean_production_companies)\n",
    "df.production_countries = df.production_countries.apply(clean_production_country)\n",
    "df.spoken_languages = df.spoken_languages.apply(clean_spoken_language)\n",
    "\n",
    "\n",
    "df = df.dropna(subset=[\"title\", \"release_date\"])\n",
    "df[\"release_date\"] = df[\"release_date\"].apply(lambda x: str(x[:4])).drop_duplicates()\n",
    "\n",
    "df[\"target\"] = df[\"revenue_right\"]\n",
    "df_final=df.drop([\"revenue\",\"revenue_right\"],axis=1)\n",
    "df_final.to_parquet(Path(dataset_dir, \"movies-yadl.parquet\"))\n",
    "df_final.to_csv(Path(dataset_dir, \"movies-yadl.csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing to the KEN version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>col_to_embed</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>30000000</td>\n",
       "      <td>Animation</td>\n",
       "      <td>862</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>21.946943</td>\n",
       "      <td>Pixar Animation Studios</td>\n",
       "      <td>US</td>\n",
       "      <td>1995</td>\n",
       "      <td>81.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Released</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415</td>\n",
       "      <td>&lt;Toy_Story&gt;</td>\n",
       "      <td>8.572353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>65000000</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>8844</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>17.015539</td>\n",
       "      <td>TriStar Pictures</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Released</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413</td>\n",
       "      <td>&lt;Jumanji&gt;</td>\n",
       "      <td>8.419621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>60000000</td>\n",
       "      <td>Action</td>\n",
       "      <td>949</td>\n",
       "      <td>en</td>\n",
       "      <td>Heat</td>\n",
       "      <td>17.924927</td>\n",
       "      <td>Regency Enterprises</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Released</td>\n",
       "      <td>Heat</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1886</td>\n",
       "      <td>&lt;Heat_(1995_film)&gt;</td>\n",
       "      <td>8.272855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>35000000</td>\n",
       "      <td>Action</td>\n",
       "      <td>9091</td>\n",
       "      <td>en</td>\n",
       "      <td>Sudden Death</td>\n",
       "      <td>5.23158</td>\n",
       "      <td>Universal Pictures</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Released</td>\n",
       "      <td>Sudden Death</td>\n",
       "      <td>False</td>\n",
       "      <td>5.5</td>\n",
       "      <td>174</td>\n",
       "      <td>&lt;Sudden_Death_(1995_film)&gt;</td>\n",
       "      <td>7.808550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Family</td>\n",
       "      <td>21032</td>\n",
       "      <td>en</td>\n",
       "      <td>Balto</td>\n",
       "      <td>12.140733</td>\n",
       "      <td>Universal Pictures</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Released</td>\n",
       "      <td>Balto</td>\n",
       "      <td>False</td>\n",
       "      <td>7.1</td>\n",
       "      <td>423</td>\n",
       "      <td>&lt;Balto_(film)&gt;</td>\n",
       "      <td>7.054932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3832</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>423453</td>\n",
       "      <td>fr</td>\n",
       "      <td>Sahara</td>\n",
       "      <td>8.665106</td>\n",
       "      <td>StudioCanal</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Released</td>\n",
       "      <td>Sahara</td>\n",
       "      <td>False</td>\n",
       "      <td>5.4</td>\n",
       "      <td>43</td>\n",
       "      <td>&lt;Sahara_(2017_film)&gt;</td>\n",
       "      <td>6.892095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>423453</td>\n",
       "      <td>fr</td>\n",
       "      <td>Sahara</td>\n",
       "      <td>8.665106</td>\n",
       "      <td>StudioCanal</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Released</td>\n",
       "      <td>Sahara</td>\n",
       "      <td>False</td>\n",
       "      <td>5.4</td>\n",
       "      <td>43</td>\n",
       "      <td>&lt;Sahara&gt;</td>\n",
       "      <td>6.892095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>265189</td>\n",
       "      <td>sv</td>\n",
       "      <td>Turist</td>\n",
       "      <td>12.165685</td>\n",
       "      <td>Motlys</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.0</td>\n",
       "      <td>Français</td>\n",
       "      <td>Released</td>\n",
       "      <td>Force Majeure</td>\n",
       "      <td>False</td>\n",
       "      <td>6.8</td>\n",
       "      <td>255</td>\n",
       "      <td>&lt;Force_Majeure_(film)&gt;</td>\n",
       "      <td>6.133378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3835</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>265189</td>\n",
       "      <td>sv</td>\n",
       "      <td>Turist</td>\n",
       "      <td>12.165685</td>\n",
       "      <td>Motlys</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.0</td>\n",
       "      <td>Français</td>\n",
       "      <td>Released</td>\n",
       "      <td>Force Majeure</td>\n",
       "      <td>False</td>\n",
       "      <td>6.8</td>\n",
       "      <td>255</td>\n",
       "      <td>&lt;Force_Majeure_(film)&gt;</td>\n",
       "      <td>6.133378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>240789</td>\n",
       "      <td>ru</td>\n",
       "      <td>Чудо</td>\n",
       "      <td>0.436028</td>\n",
       "      <td>Central Partnership</td>\n",
       "      <td>RU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Pусский</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Miracle</td>\n",
       "      <td>False</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;The_Miracle_(2009_film)&gt;</td>\n",
       "      <td>4.704631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3837 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      adult    budget     genres      id original_language original_title  \\\n",
       "0     False  30000000  Animation     862                en      Toy Story   \n",
       "1     False  65000000  Adventure    8844                en        Jumanji   \n",
       "2     False  60000000     Action     949                en           Heat   \n",
       "3     False  35000000     Action    9091                en   Sudden Death   \n",
       "4     False         0     Family   21032                en          Balto   \n",
       "...     ...       ...        ...     ...               ...            ...   \n",
       "3832  False         0  Adventure  423453                fr         Sahara   \n",
       "3833  False         0  Adventure  423453                fr         Sahara   \n",
       "3834  False         0     Comedy  265189                sv         Turist   \n",
       "3835  False         0     Comedy  265189                sv         Turist   \n",
       "3836  False         0      Drama  240789                ru           Чудо   \n",
       "\n",
       "     popularity     production_companies production_countries release_date  \\\n",
       "0     21.946943  Pixar Animation Studios                   US         1995   \n",
       "1     17.015539         TriStar Pictures                   US          NaN   \n",
       "2     17.924927      Regency Enterprises                   US          NaN   \n",
       "3       5.23158       Universal Pictures                   US          NaN   \n",
       "4     12.140733       Universal Pictures                   US          NaN   \n",
       "...         ...                      ...                  ...          ...   \n",
       "3832   8.665106              StudioCanal                   CA          NaN   \n",
       "3833   8.665106              StudioCanal                   CA          NaN   \n",
       "3834  12.165685                   Motlys                   NO          NaN   \n",
       "3835  12.165685                   Motlys                   NO          NaN   \n",
       "3836   0.436028      Central Partnership                   RU          NaN   \n",
       "\n",
       "     runtime spoken_languages    status          title  video vote_average  \\\n",
       "0       81.0          English  Released      Toy Story  False          7.7   \n",
       "1      104.0          English  Released        Jumanji  False          6.9   \n",
       "2      170.0          English  Released           Heat  False          7.7   \n",
       "3      106.0          English  Released   Sudden Death  False          5.5   \n",
       "4       78.0          English  Released          Balto  False          7.1   \n",
       "...      ...              ...       ...            ...    ...          ...   \n",
       "3832    86.0          English  Released         Sahara  False          5.4   \n",
       "3833    86.0          English  Released         Sahara  False          5.4   \n",
       "3834   118.0         Français  Released  Force Majeure  False          6.8   \n",
       "3835   118.0         Français  Released  Force Majeure  False          6.8   \n",
       "3836   110.0          Pусский  Released    The Miracle  False          6.3   \n",
       "\n",
       "     vote_count                col_to_embed    target  \n",
       "0          5415                 <Toy_Story>  8.572353  \n",
       "1          2413                   <Jumanji>  8.419621  \n",
       "2          1886          <Heat_(1995_film)>  8.272855  \n",
       "3           174  <Sudden_Death_(1995_film)>  7.808550  \n",
       "4           423              <Balto_(film)>  7.054932  \n",
       "...         ...                         ...       ...  \n",
       "3832         43        <Sahara_(2017_film)>  6.892095  \n",
       "3833         43                    <Sahara>  6.892095  \n",
       "3834        255      <Force_Majeure_(film)>  6.133378  \n",
       "3835        255      <Force_Majeure_(film)>  6.133378  \n",
       "3836          3   <The_Miracle_(2009_film)>  4.704631  \n",
       "\n",
       "[3837 rows x 19 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4_923, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>raw_entities</th><th>col_to_embed</th><th>target</th></tr><tr><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Heat&quot;</td><td>&quot;&lt;Heat_(1995_fi…</td><td>8.272855</td></tr><tr><td>&quot;Sudden Death&quot;</td><td>&quot;&lt;Sudden_Death_…</td><td>7.80855</td></tr><tr><td>&quot;Cry, the Belov…</td><td>&quot;&lt;Cry,_the_Belo…</td><td>5.830284</td></tr><tr><td>&quot;Pocahontas&quot;</td><td>&quot;&lt;Pocahontas_(1…</td><td>8.539176</td></tr><tr><td>&quot;Friday&quot;</td><td>&quot;&lt;Friday_(1995_…</td><td>7.450494</td></tr><tr><td>&quot;Fair Game&quot;</td><td>&quot;&lt;Fair_Game_(19…</td><td>7.061998</td></tr><tr><td>&quot;Bed of Roses&quot;</td><td>&quot;&lt;Bed_of_Roses_…</td><td>7.279455</td></tr><tr><td>&quot;Screamers&quot;</td><td>&quot;&lt;Screamers_(19…</td><td>6.762069</td></tr><tr><td>&quot;Black Sheep&quot;</td><td>&quot;&lt;Black_Sheep_(…</td><td>1.50515</td></tr><tr><td>&quot;Broken Arrow&quot;</td><td>&quot;&lt;Broken_Arrow_…</td><td>8.176873</td></tr><tr><td>&quot;Boomerang&quot;</td><td>&quot;&lt;Boomerang_(19…</td><td>7.845718</td></tr><tr><td>&quot;Man of the Yea…</td><td>&quot;&lt;Man_of_the_Ye…</td><td>5.322085</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Kabhi Alvida N…</td><td>&quot;&lt;Kabhi_Alvida_…</td><td>7.230449</td></tr><tr><td>&quot;The Beguiled&quot;</td><td>&quot;&lt;The_Beguiled&gt;…</td><td>7.405567</td></tr><tr><td>&quot;Desmundo&quot;</td><td>&quot;&lt;Desmundo&gt;&quot;</td><td>0.477121</td></tr><tr><td>&quot;Ed Gein&quot;</td><td>&quot;&lt;Ed_Gein&gt;&quot;</td><td>3.756484</td></tr><tr><td>&quot;The Dawns Here…</td><td>&quot;&lt;The_Dawns_Her…</td><td>6.720095</td></tr><tr><td>&quot;God of Gambler…</td><td>&quot;&lt;God_of_Gamble…</td><td>6.67782</td></tr><tr><td>&quot;I Was a Teenag…</td><td>&quot;&lt;I_Was_a_Teena…</td><td>6.30103</td></tr><tr><td>&quot;Mudhalvan&quot;</td><td>&quot;&lt;Mudhalvan&gt;&quot;</td><td>7.342423</td></tr><tr><td>&quot;Gymkata&quot;</td><td>&quot;&lt;Gymkata&gt;&quot;</td><td>6.7582</td></tr><tr><td>&quot;Moka&quot;</td><td>&quot;&lt;Moka&gt;&quot;</td><td>5.101963</td></tr><tr><td>&quot;One Hundred St…</td><td>&quot;&lt;One_Hundred_S…</td><td>6.25669</td></tr><tr><td>&quot;Sahara&quot;</td><td>&quot;&lt;Sahara&gt;&quot;</td><td>6.892095</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4_923, 3)\n",
       "┌──────────────────────────┬───────────────────────────────────┬──────────┐\n",
       "│ raw_entities             ┆ col_to_embed                      ┆ target   │\n",
       "│ ---                      ┆ ---                               ┆ ---      │\n",
       "│ str                      ┆ str                               ┆ f64      │\n",
       "╞══════════════════════════╪═══════════════════════════════════╪══════════╡\n",
       "│ Heat                     ┆ <Heat_(1995_film)>                ┆ 8.272855 │\n",
       "│ Sudden Death             ┆ <Sudden_Death_(1995_film)>        ┆ 7.80855  │\n",
       "│ Cry, the Beloved Country ┆ <Cry,_the_Beloved_Country_(1995_… ┆ 5.830284 │\n",
       "│ Pocahontas               ┆ <Pocahontas_(1995_film)>          ┆ 8.539176 │\n",
       "│ …                        ┆ …                                 ┆ …        │\n",
       "│ Gymkata                  ┆ <Gymkata>                         ┆ 6.7582   │\n",
       "│ Moka                     ┆ <Moka>                            ┆ 5.101963 │\n",
       "│ One Hundred Steps        ┆ <One_Hundred_Steps>               ┆ 6.25669  │\n",
       "│ Sahara                   ┆ <Sahara>                          ┆ 6.892095 │\n",
       "└──────────────────────────┴───────────────────────────────────┴──────────┘"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_original=Path(\"/storage/store3/work/acvetkov/gitlab/KEN/experiments/datasets/movie_revenues/target.parquet\")\n",
    "df_target_og = pl.read_parquet(path_original)\n",
    "df_target_og"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US Presidential elections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(data_dir, \"presidential-results\")\n",
    "df = pl.read_csv(Path(dataset_dir, \"presidential-results.csv\"), infer_schema_length=0)\n",
    "df = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"year\"] == \"2020\"]\n",
    "df[\"county_name\"] = df[\"county_name\"].str.title()\n",
    "df[\"state\"] = df[\"state\"].str.title()\n",
    "df[\"col_to_embed\"] = \"<\" + df[\"county_name\"] + \"_County,_\" + df[\"state\"] + \">\"\n",
    "df[\"target\"] = np.log10(df[\"candidatevotes\"].astype(int) + 1)\n",
    "df[\"raw_entities\"] = df[\"county_name\"] + \" \" + df[\"state\"]\n",
    "mask = df[\"col_to_embed\"].str.contains(\"Louisiana\")\n",
    "df.loc[mask, \"col_to_embed\"] = df.loc[mask, \"col_to_embed\"].str.replace(\n",
    "    \"County\", \"Parish\"\n",
    ")\n",
    "# df = df[[\"raw_entities\", \"col_to_embed\", \"party\", \"target\"]]\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final= df.drop(\n",
    "    [\"raw_entities\", \"candidatevotes\", \"county_fips\", \"office\", \"year\", \"totalvotes\", \"version\", \"mode\"], axis=1\n",
    ")\n",
    "df_final.to_parquet(Path(dataset_dir, \"us-presidential-results-yadl.parquet\"), index=False)\n",
    "df_final.to_csv(Path(dataset_dir, \"us-presidential-results-yadl.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\n",
    "    [\"raw_entities\", \"candidatevotes\"], axis=1\n",
    "    ).to_parquet(Path(dataset_dir, \"presidential-results-prepared.parquet\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (22_084, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>state</th><th>state_po</th><th>county_name</th><th>county_fips</th><th>office</th><th>candidate</th><th>party</th><th>totalvotes</th><th>version</th><th>mode</th><th>col_to_embed</th><th>target</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;2020&quot;</td><td>&quot;Alabama&quot;</td><td>&quot;AL&quot;</td><td>&quot;Autauga&quot;</td><td>&quot;01001&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;JOSEPH R BIDEN…</td><td>&quot;DEMOCRAT&quot;</td><td>&quot;27770&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Autauga_Count…</td><td>3.875293</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Alabama&quot;</td><td>&quot;AL&quot;</td><td>&quot;Autauga&quot;</td><td>&quot;01001&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;OTHER&quot;</td><td>&quot;OTHER&quot;</td><td>&quot;27770&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Autauga_Count…</td><td>2.633468</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Alabama&quot;</td><td>&quot;AL&quot;</td><td>&quot;Autauga&quot;</td><td>&quot;01001&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;DONALD J TRUMP…</td><td>&quot;REPUBLICAN&quot;</td><td>&quot;27770&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Autauga_Count…</td><td>4.29752</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Alabama&quot;</td><td>&quot;AL&quot;</td><td>&quot;Baldwin&quot;</td><td>&quot;01003&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;JOSEPH R BIDEN…</td><td>&quot;DEMOCRAT&quot;</td><td>&quot;109679&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Baldwin_Count…</td><td>4.390564</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Alabama&quot;</td><td>&quot;AL&quot;</td><td>&quot;Baldwin&quot;</td><td>&quot;01003&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;OTHER&quot;</td><td>&quot;OTHER&quot;</td><td>&quot;109679&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Baldwin_Count…</td><td>3.192567</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Alabama&quot;</td><td>&quot;AL&quot;</td><td>&quot;Baldwin&quot;</td><td>&quot;01003&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;DONALD J TRUMP…</td><td>&quot;REPUBLICAN&quot;</td><td>&quot;109679&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Baldwin_Count…</td><td>4.92192</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Alabama&quot;</td><td>&quot;AL&quot;</td><td>&quot;Barbour&quot;</td><td>&quot;01005&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;JOSEPH R BIDEN…</td><td>&quot;DEMOCRAT&quot;</td><td>&quot;10518&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Barbour_Count…</td><td>3.682777</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Alabama&quot;</td><td>&quot;AL&quot;</td><td>&quot;Barbour&quot;</td><td>&quot;01005&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;OTHER&quot;</td><td>&quot;OTHER&quot;</td><td>&quot;10518&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Barbour_Count…</td><td>1.908485</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Alabama&quot;</td><td>&quot;AL&quot;</td><td>&quot;Barbour&quot;</td><td>&quot;01005&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;DONALD J TRUMP…</td><td>&quot;REPUBLICAN&quot;</td><td>&quot;10518&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Barbour_Count…</td><td>3.749968</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Alabama&quot;</td><td>&quot;AL&quot;</td><td>&quot;Bibb&quot;</td><td>&quot;01007&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;JOSEPH R BIDEN…</td><td>&quot;DEMOCRAT&quot;</td><td>&quot;9595&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Bibb_County,_…</td><td>3.298198</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Alabama&quot;</td><td>&quot;AL&quot;</td><td>&quot;Bibb&quot;</td><td>&quot;01007&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;OTHER&quot;</td><td>&quot;OTHER&quot;</td><td>&quot;9595&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Bibb_County,_…</td><td>1.929419</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Alabama&quot;</td><td>&quot;AL&quot;</td><td>&quot;Bibb&quot;</td><td>&quot;01007&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;DONALD J TRUMP…</td><td>&quot;REPUBLICAN&quot;</td><td>&quot;9595&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Bibb_County,_…</td><td>3.876564</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Wyoming&quot;</td><td>&quot;WY&quot;</td><td>&quot;Uinta&quot;</td><td>&quot;56041&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;JOSEPH R BIDEN…</td><td>&quot;DEMOCRAT&quot;</td><td>&quot;9459&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Uinta_County,…</td><td>3.201943</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Wyoming&quot;</td><td>&quot;WY&quot;</td><td>&quot;Uinta&quot;</td><td>&quot;56041&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;JO JORGENSEN&quot;</td><td>&quot;LIBERTARIAN&quot;</td><td>&quot;9459&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Uinta_County,…</td><td>2.238046</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Wyoming&quot;</td><td>&quot;WY&quot;</td><td>&quot;Uinta&quot;</td><td>&quot;56041&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;OTHER&quot;</td><td>&quot;OTHER&quot;</td><td>&quot;9459&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Uinta_County,…</td><td>2.303196</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Wyoming&quot;</td><td>&quot;WY&quot;</td><td>&quot;Uinta&quot;</td><td>&quot;56041&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;DONALD J TRUMP…</td><td>&quot;REPUBLICAN&quot;</td><td>&quot;9459&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Uinta_County,…</td><td>3.874888</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Wyoming&quot;</td><td>&quot;WY&quot;</td><td>&quot;Washakie&quot;</td><td>&quot;56043&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;JOSEPH R BIDEN…</td><td>&quot;DEMOCRAT&quot;</td><td>&quot;4032&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Washakie_Coun…</td><td>2.814248</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Wyoming&quot;</td><td>&quot;WY&quot;</td><td>&quot;Washakie&quot;</td><td>&quot;56043&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;JO JORGENSEN&quot;</td><td>&quot;LIBERTARIAN&quot;</td><td>&quot;4032&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Washakie_Coun…</td><td>1.819544</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Wyoming&quot;</td><td>&quot;WY&quot;</td><td>&quot;Washakie&quot;</td><td>&quot;56043&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;OTHER&quot;</td><td>&quot;OTHER&quot;</td><td>&quot;4032&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Washakie_Coun…</td><td>1.857332</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Wyoming&quot;</td><td>&quot;WY&quot;</td><td>&quot;Washakie&quot;</td><td>&quot;56043&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;DONALD J TRUMP…</td><td>&quot;REPUBLICAN&quot;</td><td>&quot;4032&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Washakie_Coun…</td><td>3.511349</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Wyoming&quot;</td><td>&quot;WY&quot;</td><td>&quot;Weston&quot;</td><td>&quot;56045&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;JOSEPH R BIDEN…</td><td>&quot;DEMOCRAT&quot;</td><td>&quot;3560&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Weston_County…</td><td>2.557507</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Wyoming&quot;</td><td>&quot;WY&quot;</td><td>&quot;Weston&quot;</td><td>&quot;56045&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;JO JORGENSEN&quot;</td><td>&quot;LIBERTARIAN&quot;</td><td>&quot;3560&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Weston_County…</td><td>1.672098</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Wyoming&quot;</td><td>&quot;WY&quot;</td><td>&quot;Weston&quot;</td><td>&quot;56045&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;OTHER&quot;</td><td>&quot;OTHER&quot;</td><td>&quot;3560&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Weston_County…</td><td>1.681241</td></tr><tr><td>&quot;2020&quot;</td><td>&quot;Wyoming&quot;</td><td>&quot;WY&quot;</td><td>&quot;Weston&quot;</td><td>&quot;56045&quot;</td><td>&quot;US PRESIDENT&quot;</td><td>&quot;DONALD J TRUMP…</td><td>&quot;REPUBLICAN&quot;</td><td>&quot;3560&quot;</td><td>&quot;20220315&quot;</td><td>&quot;TOTAL&quot;</td><td>&quot;&lt;Weston_County…</td><td>3.492481</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (22_084, 13)\n",
       "┌──────┬─────────┬──────────┬─────────────┬───┬──────────┬───────┬──────────────────────┬──────────┐\n",
       "│ year ┆ state   ┆ state_po ┆ county_name ┆ … ┆ version  ┆ mode  ┆ col_to_embed         ┆ target   │\n",
       "│ ---  ┆ ---     ┆ ---      ┆ ---         ┆   ┆ ---      ┆ ---   ┆ ---                  ┆ ---      │\n",
       "│ str  ┆ str     ┆ str      ┆ str         ┆   ┆ str      ┆ str   ┆ str                  ┆ f64      │\n",
       "╞══════╪═════════╪══════════╪═════════════╪═══╪══════════╪═══════╪══════════════════════╪══════════╡\n",
       "│ 2020 ┆ Alabama ┆ AL       ┆ Autauga     ┆ … ┆ 20220315 ┆ TOTAL ┆ <Autauga_County,_Ala ┆ 3.875293 │\n",
       "│      ┆         ┆          ┆             ┆   ┆          ┆       ┆ bama>                ┆          │\n",
       "│ 2020 ┆ Alabama ┆ AL       ┆ Autauga     ┆ … ┆ 20220315 ┆ TOTAL ┆ <Autauga_County,_Ala ┆ 2.633468 │\n",
       "│      ┆         ┆          ┆             ┆   ┆          ┆       ┆ bama>                ┆          │\n",
       "│ 2020 ┆ Alabama ┆ AL       ┆ Autauga     ┆ … ┆ 20220315 ┆ TOTAL ┆ <Autauga_County,_Ala ┆ 4.29752  │\n",
       "│      ┆         ┆          ┆             ┆   ┆          ┆       ┆ bama>                ┆          │\n",
       "│ 2020 ┆ Alabama ┆ AL       ┆ Baldwin     ┆ … ┆ 20220315 ┆ TOTAL ┆ <Baldwin_County,_Ala ┆ 4.390564 │\n",
       "│      ┆         ┆          ┆             ┆   ┆          ┆       ┆ bama>                ┆          │\n",
       "│ …    ┆ …       ┆ …        ┆ …           ┆ … ┆ …        ┆ …     ┆ …                    ┆ …        │\n",
       "│ 2020 ┆ Wyoming ┆ WY       ┆ Weston      ┆ … ┆ 20220315 ┆ TOTAL ┆ <Weston_County,_Wyom ┆ 2.557507 │\n",
       "│      ┆         ┆          ┆             ┆   ┆          ┆       ┆ ing>                 ┆          │\n",
       "│ 2020 ┆ Wyoming ┆ WY       ┆ Weston      ┆ … ┆ 20220315 ┆ TOTAL ┆ <Weston_County,_Wyom ┆ 1.672098 │\n",
       "│      ┆         ┆          ┆             ┆   ┆          ┆       ┆ ing>                 ┆          │\n",
       "│ 2020 ┆ Wyoming ┆ WY       ┆ Weston      ┆ … ┆ 20220315 ┆ TOTAL ┆ <Weston_County,_Wyom ┆ 1.681241 │\n",
       "│      ┆         ┆          ┆             ┆   ┆          ┆       ┆ ing>                 ┆          │\n",
       "│ 2020 ┆ Wyoming ┆ WY       ┆ Weston      ┆ … ┆ 20220315 ┆ TOTAL ┆ <Weston_County,_Wyom ┆ 3.492481 │\n",
       "│      ┆         ┆          ┆             ┆   ┆          ┆       ┆ ing>                 ┆          │\n",
       "└──────┴─────────┴──────────┴─────────────┴───┴──────────┴───────┴──────────────────────┴──────────┘"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_parquet(Path(dataset_dir, \"presidential-results-prepared.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/workspace/tmp/ipykernel_21676/1115888739.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df=df.groupby([\"raw_entities\", \"col_to_embed\", \"party\"], as_index=False).sum()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df=df.groupby([\"raw_entities\", \"col_to_embed\", \"party\"], as_index=False).sum()\n",
    "\n",
    "df[\"col_to_embed\"] = df[\"col_to_embed\"].str.replace(\" \", \"_\")\n",
    "mask = df[\"col_to_embed\"].str.contains(\"Louisiana\")\n",
    "df.loc[mask, \"col_to_embed\"] = df.loc[mask, \"col_to_embed\"].str.replace(\n",
    "    \"County\", \"Parish\"\n",
    ")\n",
    "df[\"col_to_embed\"] = df[\"col_to_embed\"].str.replace(\"_City_County\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
